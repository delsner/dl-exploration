{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM sentiment classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle as p\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart: simple NN in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input_nodes = 2\n",
    "n_output_nodes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, n_input_nodes))\n",
    "W = tf.Variable(tf.ones((n_input_nodes, n_output_nodes)), dtype=tf.float32)\n",
    "b = tf.Variable(tf.zeros(n_output_nodes), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tf.matmul(x, W) + b\n",
    "out = tf.sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.7310586]]\n"
     ]
    }
   ],
   "source": [
    "test_input = [[0.5, 0.5]]\n",
    "with tf.Session() as session:\n",
    "    init = tf.global_variables_initializer()\n",
    "    session.run(init)\n",
    "    feed_dict = {x: test_input}\n",
    "    output = session.run([out], feed_dict=feed_dict)\n",
    "    print(output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTMs for Tweet Sentiment Classification \n",
    " \n",
    "see https://github.com/nicholaslocascio/bcs-lstm/blob/master/Lab.ipynb\n",
    "\n",
    "Sentiment classification will be done based on words, not on characters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set variables\n",
    "tweet_size = 20\n",
    "hidden_size = 100\n",
    "vocab_size = 7597 # amount of words in our vocabulary\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this just makes sure that all our following operations will be placed in the right graph.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# create a session variable that we can run later.\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders for input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size x tweet_size (each word in tweet) x one_hot_vector of size vocab_size\n",
    "tweets = tf.placeholder(dtype=tf.float32, shape=[None, tweet_size, vocab_size])\n",
    "# 1d vector of size batch_size as we predict one value per tweet in batch\n",
    "labels = tf.placeholder(dtype=tf.float32, shape=[None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build LSTM layers\n",
    "\n",
    "We want to feed the input sequence, word by word, into an LSTM layer, or multiple LSTM layers (we could also call this an **LSTM encoder**). At each \"timestep\", we feed in the next word, and the LSTM updates its cell state. The final LSTM cell state can then be fed through a final classification layer(s) to get our sentiment prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 2 LSTM cells -> creates a layer of LSTM cells not just a single one\n",
    "lstm_cell_1 = tf.contrib.rnn.LSTMCell(hidden_size)\n",
    "lstm_cell_2 = tf.contrib.rnn.LSTMCell(hidden_size)\n",
    "\n",
    "# create multiple LSTM layers by wrapping the two lstm cells in MultiRNNCell\n",
    "multi_lstm_cells = tf.contrib.rnn.MultiRNNCell([lstm_cell_1, lstm_cell_2], state_is_tuple=True)\n",
    "\n",
    "# define operation that runs LSTM graph across time, on the data\n",
    "_, final_state = tf.nn.dynamic_rnn(multi_lstm_cells, tweets, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification layer\n",
    "\n",
    "Once we have the final state of the LSTM layers after feeding in the tweet word by word we can take it and feed it into a classfication layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to create a weight matrix + bias parameters and matrix multiplication\n",
    "def linear(input_, output_size, name, init_bias=0.0):\n",
    "    shape = input_.get_shape().as_list()\n",
    "    with tf.variable_scope(name):\n",
    "        W = tf.get_variable(\n",
    "            name='weights',\n",
    "            shape=[shape[-1], output_size],\n",
    "            dtype=tf.float32,\n",
    "            initializer=tf.random_normal_initializer(\n",
    "                stddev=1.0 / math.sqrt(shape[-1])))\n",
    "    if init_bias is None:\n",
    "        return tf.matmul(input_, W)\n",
    "    with tf.variable_scope(name):\n",
    "        b = tf.get_variable(\n",
    "            name='bias',\n",
    "            shape=[output_size],\n",
    "            initializer=tf.constant_initializer(init_bias))\n",
    "    return tf.matmul(input_, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "   {Quick note that we need to feed in final_state[-1][-1] into linear since \n",
    "   final_state is actually a tuple consisting of the cell state \n",
    "   (used internally for the cell to keep track of things) \n",
    "   as well as the hidden state (the output of the cell), and one of these \n",
    "   tuples for each layer. We want the hidden state for the last layer, so we use \n",
    "   final_state[-1][-1]}''';\n",
    "# pass final state into linear function to get output\n",
    "sentiment = linear(final_state[-1][-1], 1, 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss (cross-entropy) -> output of classfication layer (logit) needs to be transformed to probability in [0,1] -> use sigmoid\n",
    "sentiment = tf.squeeze(sentiment, [1])\n",
    "\n",
    "# gives loss for each example in batch\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=sentiment, labels=labels)\n",
    "\n",
    "# take mean of all losses\n",
    "loss = tf.reduce_mean(loss)\n",
    "\n",
    "# round probilities to get 1 or 0 classfication\n",
    "prob = tf.nn.sigmoid(sentiment)\n",
    "prediction = tf.to_float(tf.greater_equal(prob, 0.5))\n",
    "\n",
    "# calculate sum of errors based on which predictions were actually correct\n",
    "pred_err = tf.to_float(tf.not_equal(prediction, labels))\n",
    "pred_err = tf.reduce_sum(pred_err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train model - define optimizer (adam)\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize variables\n",
    "tf.global_variables_initializer().run(session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(raw_data, vocab_size):\n",
    "    data = np.zeros((len(raw_data), 20, vocab_size))\n",
    "    for tweet_index in range(len(raw_data)):\n",
    "        tweet = raw_data[tweet_index]\n",
    "        for word_index in range(20):\n",
    "            word_id = tweet[word_index]\n",
    "            data[tweet_index, word_index, word_id] = 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 345   55 3679 1796   30    7  211  474  260   29   59   33    1    1\n",
      "     1    1    1    1    1    1]\n",
      " [  20 1563    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "     1    1    1    1    1    1]\n",
      " [ 256   75 1172    1    1    1    1    1    1    1    1    1    1    1\n",
      "     1    1    1    1    1    1]\n",
      " [   2    2  100  704    9  414   17  236 1280    1    1    1    1    1\n",
      "     1    1    1    1    1    1]\n",
      " [ 361 1324    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "     1    1    1    1    1    1]]\n",
      "[0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# load data and separate into tweets and labels\n",
    "train_data = json.load(open('trainTweets_preprocessed.json', 'r'))\n",
    "train_data = list(\n",
    "    map(lambda row: (np.array(row[0], dtype=np.int32), str(row[1])),\n",
    "        train_data))\n",
    "train_tweets = np.array([t[0] for t in train_data])\n",
    "train_labels = np.array([int(t[1]) for t in train_data])\n",
    "\n",
    "test_data = json.load(open('testTweets_preprocessed.json', 'r'))\n",
    "test_data = list(\n",
    "    map(lambda row: (np.array(row[0], dtype=np.int32), str(row[1])),\n",
    "        test_data))\n",
    "\n",
    "print(train_tweets[:5])\n",
    "print(train_labels[:5])\n",
    "# we are just taking the first 1000 things from the test set for faster evaluation\n",
    "test_data = test_data[0:1000]\n",
    "test_tweets = np.array([t[0] for t in test_data])\n",
    "one_hot_test_tweets = one_hot(test_tweets, vocab_size)\n",
    "test_labels = np.array([int(t[1]) for t in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we'll train with batches of size 64.  This means that we run \n",
    "# our model on 64 examples and then do gradient descent based on the loss\n",
    "# over those 64 examples.\n",
    "num_steps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch train loss at step 0 : 0.693044\n",
      "Minibatch train error: 27.000%\n",
      "Test loss: 0.692\n",
      "Test error: 28.200%\n",
      "Minibatch train loss at step 50 : 0.541591\n",
      "Minibatch train error: 18.000%\n",
      "Test loss: 0.619\n",
      "Test error: 22.667%\n",
      "Minibatch train loss at step 100 : 0.5981\n",
      "Minibatch train error: 22.000%\n",
      "Test loss: 0.584\n",
      "Test error: 20.333%\n",
      "Minibatch train loss at step 150 : 0.558191\n",
      "Minibatch train error: 15.000%\n",
      "Test loss: 0.575\n",
      "Test error: 18.733%\n",
      "Minibatch train loss at step 200 : 0.510845\n",
      "Minibatch train error: 16.000%\n",
      "Test loss: 0.547\n",
      "Test error: 17.400%\n",
      "Minibatch train loss at step 250 : 0.453754\n",
      "Minibatch train error: 17.000%\n",
      "Test loss: 0.533\n",
      "Test error: 16.600%\n",
      "Minibatch train loss at step 300 : 0.591443\n",
      "Minibatch train error: 17.000%\n",
      "Test loss: 0.534\n",
      "Test error: 16.400%\n",
      "Minibatch train loss at step 350 : 0.537777\n",
      "Minibatch train error: 18.000%\n",
      "Test loss: 0.547\n",
      "Test error: 17.067%\n",
      "Minibatch train loss at step 400 : 0.563265\n",
      "Minibatch train error: 17.000%\n",
      "Test loss: 0.523\n",
      "Test error: 15.533%\n",
      "Minibatch train loss at step 450 : 0.583196\n",
      "Minibatch train error: 19.000%\n",
      "Test loss: 0.534\n",
      "Test error: 16.533%\n",
      "Minibatch train loss at step 500 : 0.552881\n",
      "Minibatch train error: 18.000%\n",
      "Test loss: 0.517\n",
      "Test error: 15.867%\n",
      "Minibatch train loss at step 550 : 0.575206\n",
      "Minibatch train error: 20.000%\n",
      "Test loss: 0.513\n",
      "Test error: 16.067%\n",
      "Minibatch train loss at step 600 : 0.425225\n",
      "Minibatch train error: 11.000%\n",
      "Test loss: 0.520\n",
      "Test error: 16.867%\n",
      "Minibatch train loss at step 650 : 0.551344\n",
      "Minibatch train error: 16.000%\n",
      "Test loss: 0.515\n",
      "Test error: 15.333%\n",
      "Minibatch train loss at step 700 : 0.464163\n",
      "Minibatch train error: 16.000%\n",
      "Test loss: 0.505\n",
      "Test error: 14.600%\n",
      "Minibatch train loss at step 750 : 0.596228\n",
      "Minibatch train error: 16.000%\n",
      "Test loss: 0.507\n",
      "Test error: 15.467%\n",
      "Minibatch train loss at step 800 : 0.586395\n",
      "Minibatch train error: 18.000%\n",
      "Test loss: 0.509\n",
      "Test error: 15.800%\n",
      "Minibatch train loss at step 850 : 0.470788\n",
      "Minibatch train error: 12.000%\n",
      "Test loss: 0.512\n",
      "Test error: 15.533%\n",
      "Minibatch train loss at step 900 : 0.520554\n",
      "Minibatch train error: 15.000%\n",
      "Test loss: 0.510\n",
      "Test error: 16.200%\n",
      "Minibatch train loss at step 950 : 0.381157\n",
      "Minibatch train error: 10.000%\n",
      "Test loss: 0.504\n",
      "Test error: 15.533%\n"
     ]
    }
   ],
   "source": [
    "for step in range(num_steps):\n",
    "    # get data for a batch\n",
    "    offset = (step * batch_size) % (len(train_data) - batch_size)\n",
    "    batch_tweets = one_hot(train_tweets[offset:(offset + batch_size)],\n",
    "                                 vocab_size)\n",
    "    batch_labels = train_labels[offset:(offset + batch_size)]\n",
    "\n",
    "    # put this data into a dictionary that we feed in when we run\n",
    "    # the graph.  this data fills in the placeholders we made in the graph.\n",
    "    data = {tweets: batch_tweets, labels: batch_labels}\n",
    "\n",
    "    # run the 'optimizer', 'loss', and 'pred_err' operations in the graph\n",
    "    _, loss_value_train, error_value_train = session.run(\n",
    "        [optimizer, loss, pred_err], feed_dict=data)\n",
    "\n",
    "    # print stuff every 50 steps to see how we are doing\n",
    "    if (step % 50 == 0):\n",
    "        print(\"Minibatch train loss at step\", step, \":\", loss_value_train)\n",
    "        print(\"Minibatch train error: %.3f%%\" % error_value_train)\n",
    "\n",
    "        # get test evaluation\n",
    "        test_loss = []\n",
    "        test_error = []\n",
    "        for batch_num in range(int(len(test_data) / batch_size)):\n",
    "            test_offset = (batch_num * batch_size) % (\n",
    "                len(test_data) - batch_size)\n",
    "            test_batch_tweets = one_hot_test_tweets[test_offset:(\n",
    "                test_offset + batch_size)]\n",
    "            test_batch_labels = test_labels[test_offset:(\n",
    "                test_offset + batch_size)]\n",
    "            data_testing = {\n",
    "                tweets: test_batch_tweets,\n",
    "                labels: test_batch_labels\n",
    "            }\n",
    "            loss_value_test, error_value_test = session.run(\n",
    "                [loss, pred_err], feed_dict=data_testing)\n",
    "            test_loss.append(loss_value_test)\n",
    "            test_error.append(error_value_test)\n",
    "\n",
    "        print(\"Test loss: %.3f\" % np.mean(test_loss))\n",
    "        print(\"Test error: %.3f%%\" % np.mean(test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
